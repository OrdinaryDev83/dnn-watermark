{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from transformers import DetrFeatureExtractor, AutoModelForObjectDetection, TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Detr Resnet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"logo\": 0,\n",
    "    \"text\": 1,\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor_checkpoint = \"facebook/detr-resnet-50\"\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(feature_extractor_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    feature_extractor_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bastienp/visible-watermark-pita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = A.Compose([\n",
    "    A.Resize(480, 480),\n",
    "    A.CenterCrop(224, 224),\n",
    "], bbox_params=A.BboxParams(format=\"coco\", label_fields=[]))\n",
    "\n",
    "preprocess_viz = A.Compose([\n",
    "    A.Resize(480, 480),\n",
    "    A.CenterCrop(224, 224),\n",
    "], bbox_params=A.BboxParams(format=\"coco\", label_fields=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_coco_bbox(bbox, img_width, img_height):\n",
    "    x, y, width, height = bbox\n",
    "    \n",
    "    # Ensure x and y are within the image boundaries\n",
    "    x = max(0, min(x, img_width))\n",
    "    y = max(0, min(y, img_height))\n",
    "    \n",
    "    # Ensure width and height do not extend beyond the image boundaries\n",
    "    width = min(width, img_width - x)\n",
    "    height = min(height, img_height - y)\n",
    "    \n",
    "    return [x, y, width, height]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def formatted_anns(image_id, category, area, bbox):\n",
    "    annotations = []\n",
    "    for i in range(0, len(category)):\n",
    "        new_ann = {\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": category[i],\n",
    "            \"isCrowd\": 0,\n",
    "            \"area\": area[i],\n",
    "            \"bbox\": list(bbox[i]),\n",
    "        }\n",
    "        annotations.append(new_ann)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming a batch\n",
    "def transform_aug_ann(examples):\n",
    "    image_ids = examples[\"image_id\"]\n",
    "    images, bboxes, areas, categories = [], [], [], []\n",
    "    for image, bbox, category, area in zip(examples[\"image\"], examples[\"bbox\"], examples[\"category_id\"], examples[\"area\"]):\n",
    "        image = np.array(image.convert(\"RGB\"))\n",
    "        img_shape = image.shape\n",
    "\n",
    "        out = preprocess(image=image, bboxes=[clamp_coco_bbox(bb, img_shape[0], img_shape[1]) for bb in [bbox]], category_ids=[category])\n",
    "\n",
    "        areas.append([area])\n",
    "        images.append(out[\"image\"])\n",
    "        bboxes.append(out[\"bboxes\"])\n",
    "        categories.append(out[\"category_ids\"])\n",
    "\n",
    "    targets = [\n",
    "        {\"image_id\": id_, \"annotations\": formatted_anns(id_, cat_, ar_, box_)}\n",
    "        for id_, cat_, ar_, box_ in zip(image_ids, categories, areas, bboxes)\n",
    "    ]\n",
    "\n",
    "    return feature_extractor(images=images, annotations=targets, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].with_transform(transform_aug_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    encoding = feature_extractor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"detr-resnet-50_finetuned\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=1e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    tokenizer=feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"detr-resnet-50_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame(trainer.state.log_history)\n",
    "\n",
    "df_logs[[\"loss\", \"learning_rate\"]].plot(title=\"Training Metrics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
